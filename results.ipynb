{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/coco\"\n",
    "\n",
    "IMG_HEIGHT = 244\n",
    "IMG_WIDTH = 244\n",
    "\n",
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Setup GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image data\n",
    "image_filenames = {}\n",
    "image_dir = DATA_DIR + \"/val2017/\"\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        image_filenames[int(filename[:-4])] = image_dir + filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bbox/annotations\n",
    "with open(DATA_DIR + \"/annotations/instances_val2017.json\") as f:\n",
    "    _ = json.load(f)\n",
    "    categories = {entry[\"id\"]:{\n",
    "            \"supercategory\": entry[\"supercategory\"],\n",
    "            \"name\": entry[\"name\"]\n",
    "        } for entry in _[\"categories\"]}\n",
    "    instances = {entry[\"id\"]:{\n",
    "            \"bbox\": tuple(entry[\"bbox\"]),\n",
    "            \"category_id\": entry[\"category_id\"],\n",
    "            \"image_id\": entry[\"image_id\"]\n",
    "        } for entry in _[\"annotations\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIGGER_THRESHOLD = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent.infrastructure.env import ObjectLocalizationEnv, BetterRewardEnv, MovingEdgeEnv, HierarchicalZoomEnv, StretchyZoomEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential(tf.keras.applications.VGG16(weights=\"imagenet\", include_top = True).layers[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_env = ObjectLocalizationEnv(model, (224, 224), feature_dim = 4096, trigger_threshold = TRIGGER_THRESHOLD)\n",
    "moving_edge_env = MovingEdgeEnv(model, (244, 244), feature_dim = 4096, transformation_factor = 0.4, trigger_threshold = TRIGGER_THRESHOLD)\n",
    "zoomzoom_env = HierarchicalZoomEnv(model, (244,244), feature_dim = 4096, trigger_threshold = TRIGGER_THRESHOLD)\n",
    "stretchyzoom_env = StretchyZoomEnv(model, (244,244), feature_dim = 4096, trigger_threshold = TRIGGER_THRESHOLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent.infrastructure.trainer import RL_Trainer\n",
    "from multiagent.agents.dqn_agent import DQN_Agent\n",
    "from multiagent.util.dqn_utils import EpochSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_params = { #TODO!!!!\n",
    "    \"replay_buffer_size\": 500,\n",
    "    \"batch_size\": 32,\n",
    "    \"gamma\": 0.1,\n",
    "    \"epsilon\": EpochSchedule(15, final_p = .1, initial_p = 1),\n",
    "    \"dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_freq\": 1,\n",
    "    \"seed\": SEED,\n",
    "    \"agent_class\": DQN_Agent,\n",
    "    \"optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    \"loss\": tf.keras.losses.Huber(),\n",
    "    \"agent_params\": agent_params,\n",
    "    \"env\": None, #PlaceHolder\n",
    "    \"max_path_length\": 200,\n",
    "    \"model_name\": \"austensux\", #PlaceHolder\n",
    "    \"save_freq\": 0 #Manually save after every epoch\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curating category-specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY_ID = 1\n",
    "CATEGORY_NAME = categories[CATEGORY_ID][\"name\"]\n",
    "NUM_EVAL = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2693 images that include at least one instance of 'person'\n"
     ]
    }
   ],
   "source": [
    "from multiagent.util.data import find_all_instances, find_image_ids_with_category, process_image_filename, stream_images\n",
    "\n",
    "category_image_ids = find_image_ids_with_category(instances, CATEGORY_ID)\n",
    "print(\"{} images that include at least one instance of '{}'\".format(len(category_image_ids), categories[CATEGORY_ID][\"name\"]))\n",
    "category_image_ids = sorted(category_image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/moving_edge/epoch2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_q_func = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_agent_params = deepcopy(agent_params)\n",
    "\n",
    "params['env'] = stretchyzoom_env\n",
    "params['model_name'] = \"moving_edge\"\n",
    "params['agent_params'] = current_agent_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RL_Trainer(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.agent.q_func = loaded_q_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_bboxs(image_id, category_name, bboxs, directory, detection):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(directory + str(image_id) + \".txt\",\"w+\") as f:\n",
    "        for bbox in bboxs:\n",
    "            if detection:\n",
    "                confidence = 1\n",
    "                f.write(\"{} {} {} {} {} {}\\n\".format(category_name, confidence, *bbox))\n",
    "            else:\n",
    "                f.write(\"{} {} {} {} {}\\n\".format(category_name, *bbox))\n",
    "        f.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_DIR = \"eval/{}/groundtruths/\".format(params[\"model_name\"])\n",
    "DETECTIONS_DIR = \"eval/{}/detections/\".format(params[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_image_iter = 0\n",
    "# category_images = stream_images(category_image_ids, image_filenames, limit=NUM_EVAL)\n",
    "\n",
    "# for image_id, image_tensor in category_images:\n",
    "#     current_image_iter += 1\n",
    "#     print(\"\\n\\n####### Testing image '{}' which is {} of {}\".format(image_id, current_image_iter, NUM_EVAL))\n",
    "\n",
    "#     keys, target_bboxs = find_all_instances(instances, image_id, CATEGORY_ID)\n",
    "#     image_tensor = tf.expand_dims(image_tensor, 0)\n",
    "\n",
    "#     # have agent look for bboxs\n",
    "#     trainer.env.training_reset(target_bboxs, image_tensor)\n",
    "#     detections = trainer.eval(1)\n",
    "#     print(\"{} unfound instances out of {}\".format(len(trainer.env.target_bboxs), len(trainer.env.orig_target_bboxs)))\n",
    "    \n",
    "#     # save bboxs\n",
    "#     save_bboxs(image_id, CATEGORY_NAME, target_bboxs, GROUND_TRUTH_DIR, False)\n",
    "#     save_bboxs(image_id, CATEGORY_NAME, detections, DETECTIONS_DIR, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expert sequence distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "####### Image '139' which is 1 of 100\n",
      "22, \n",
      "1 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '785' which is 2 of 100\n",
      "3, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '872' which is 3 of 100\n",
      "3, 4, \n",
      "0 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '885' which is 4 of 100\n",
      "20, 5, \n",
      "6 unfound instances out of 8\n",
      "\n",
      "\n",
      "####### Image '1000' which is 5 of 100\n",
      "7, 13, 6, \n",
      "9 unfound instances out of 12\n",
      "\n",
      "\n",
      "####### Image '1268' which is 6 of 100\n",
      "8, \n",
      "3 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '1296' which is 7 of 100\n",
      "1, 17, \n",
      "0 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '1353' which is 8 of 100\n",
      "6, 5, 26, 10, 8, 10, \n",
      "0 unfound instances out of 6\n",
      "\n",
      "\n",
      "####### Image '1490' which is 9 of 100\n",
      "\n",
      "1 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '1584' which is 10 of 100\n",
      "12, \n",
      "10 unfound instances out of 11\n",
      "\n",
      "\n",
      "####### Image '1761' which is 11 of 100\n",
      "19, 33, \n",
      "3 unfound instances out of 5\n",
      "\n",
      "\n",
      "####### Image '2006' which is 12 of 100\n",
      "24, \n",
      "2 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '2153' which is 13 of 100\n",
      "23, 20, 7, \n",
      "1 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '2261' which is 14 of 100\n",
      "7, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '2299' which is 15 of 100\n",
      "1, 26, 29, 17, 30, 7, 28, 6, \n",
      "6 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '2431' which is 16 of 100\n",
      "31, 41, \n",
      "0 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '2473' which is 17 of 100\n",
      "14, 9, \n",
      "2 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '2532' which is 18 of 100\n",
      "13, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '2685' which is 19 of 100\n",
      "2, 15, 22, 4, 32, 8, \n",
      "0 unfound instances out of 6\n",
      "\n",
      "\n",
      "####### Image '3156' which is 20 of 100\n",
      "1, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '3255' which is 21 of 100\n",
      "33, \n",
      "5 unfound instances out of 6\n",
      "\n",
      "\n",
      "####### Image '3553' which is 22 of 100\n",
      "24, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '3934' which is 23 of 100\n",
      "4, 27, 14, \n",
      "4 unfound instances out of 7\n",
      "\n",
      "\n",
      "####### Image '4134' which is 24 of 100\n",
      "2, 2, \n",
      "11 unfound instances out of 13\n",
      "\n",
      "\n",
      "####### Image '4395' which is 25 of 100\n",
      "1, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '4765' which is 26 of 100\n",
      "5, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '5001' which is 27 of 100\n",
      "8, 23, 5, 40, 28, \n",
      "9 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '5037' which is 28 of 100\n",
      "10, 16, 14, \n",
      "4 unfound instances out of 7\n",
      "\n",
      "\n",
      "####### Image '5060' which is 29 of 100\n",
      "6, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '5193' which is 30 of 100\n",
      "19, 12, \n",
      "4 unfound instances out of 6\n",
      "\n",
      "\n",
      "####### Image '5529' which is 31 of 100\n",
      "4, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '5586' which is 32 of 100\n",
      "1, 35, 8, 41, 11, \n",
      "9 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '6040' which is 33 of 100\n",
      "30, 41, 14, \n",
      "6 unfound instances out of 9\n",
      "\n",
      "\n",
      "####### Image '6460' which is 34 of 100\n",
      "11, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '6471' which is 35 of 100\n",
      "5, 14, 18, \n",
      "7 unfound instances out of 10\n",
      "\n",
      "\n",
      "####### Image '6763' which is 36 of 100\n",
      "2, 2, 33, \n",
      "0 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '6771' which is 37 of 100\n",
      "3, 27, 11, 4, \n",
      "4 unfound instances out of 8\n",
      "\n",
      "\n",
      "####### Image '6894' which is 38 of 100\n",
      "1, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '6954' which is 39 of 100\n",
      "6, 18, 21, 23, \n",
      "1 unfound instances out of 5\n",
      "\n",
      "\n",
      "####### Image '7088' which is 40 of 100\n",
      "6, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '7278' which is 41 of 100\n",
      "9, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '7281' which is 42 of 100\n",
      "25, \n",
      "9 unfound instances out of 10\n",
      "\n",
      "\n",
      "####### Image '7511' which is 43 of 100\n",
      "25, 9, \n",
      "12 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '7816' which is 44 of 100\n",
      "24, 10, 20, 12, \n",
      "6 unfound instances out of 10\n",
      "\n",
      "\n",
      "####### Image '7977' which is 45 of 100\n",
      "5, \n",
      "4 unfound instances out of 5\n",
      "\n",
      "\n",
      "####### Image '8021' which is 46 of 100\n",
      "16, 5, 20, \n",
      "0 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '8211' which is 47 of 100\n",
      "\n",
      "2 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '8532' which is 48 of 100\n",
      "1, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '8690' which is 49 of 100\n",
      "4, 2, \n",
      "2 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '8844' which is 50 of 100\n",
      "5, 11, 41, \n",
      "0 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '9378' which is 51 of 100\n",
      "1, 37, 11, \n",
      "6 unfound instances out of 9\n",
      "\n",
      "\n",
      "####### Image '9400' which is 52 of 100\n",
      "20, 20, 24, 7, 7, 8, \n",
      "3 unfound instances out of 9\n",
      "\n",
      "\n",
      "####### Image '9448' which is 53 of 100\n",
      "2, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '9483' which is 54 of 100\n",
      "\n",
      "1 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '9590' which is 55 of 100\n",
      "7, 9, \n",
      "4 unfound instances out of 6\n",
      "\n",
      "\n",
      "####### Image '9769' which is 56 of 100\n",
      "12, 35, \n",
      "1 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '9772' which is 57 of 100\n",
      "10, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '9891' which is 58 of 100\n",
      "4, 29, 11, 26, \n",
      "0 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '10707' which is 59 of 100\n",
      "7, 4, \n",
      "1 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '10764' which is 60 of 100\n",
      "3, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '11051' which is 61 of 100\n",
      "1, 6, \n",
      "0 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '11149' which is 62 of 100\n",
      "8, \n",
      "1 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '11197' which is 63 of 100\n",
      "40, \n",
      "4 unfound instances out of 5\n",
      "\n",
      "\n",
      "####### Image '11511' which is 64 of 100\n",
      "\n",
      "4 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '11699' which is 65 of 100\n",
      "16, 26, 28, \n",
      "0 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '12120' which is 66 of 100\n",
      "1, \n",
      "13 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '12280' which is 67 of 100\n",
      "23, \n",
      "2 unfound instances out of 3\n",
      "\n",
      "\n",
      "####### Image '12576' which is 68 of 100\n",
      "6, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '12639' which is 69 of 100\n",
      "5, 5, 35, 21, \n",
      "10 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '12670' which is 70 of 100\n",
      "1, 23, 40, 6, 8, 9, 7, 25, \n",
      "6 unfound instances out of 14\n",
      "\n",
      "\n",
      "####### Image '12748' which is 71 of 100\n",
      "2, 3, \n",
      "0 unfound instances out of 2\n",
      "\n",
      "\n",
      "####### Image '13177' which is 72 of 100\n",
      "3, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '13201' which is 73 of 100\n",
      "2, \n",
      "0 unfound instances out of 1\n",
      "\n",
      "\n",
      "####### Image '13291' which is 74 of 100\n",
      "6, 17, 7, 6, \n",
      "0 unfound instances out of 4\n",
      "\n",
      "\n",
      "####### Image '13348' which is 75 of 100\n",
      "19, "
     ]
    }
   ],
   "source": [
    "dist = []\n",
    "\n",
    "category_images = stream_images(category_image_ids, image_filenames, limit=NUM_EVAL)\n",
    "\n",
    "current_image_iter = 0\n",
    "early_terminated = 0\n",
    "for image_id, image_tensor in category_images:\n",
    "    current_image_iter += 1\n",
    "    print(\"\\n\\n####### Image '{}' which is {} of {}\".format(image_id, current_image_iter, NUM_EVAL))\n",
    "    keys, target_bboxs = find_all_instances(instances, image_id, CATEGORY_ID)\n",
    "    image_tensor = tf.expand_dims(image_tensor, 0)\n",
    "    \n",
    "    trainer.env.training_reset(target_bboxs, image_tensor)\n",
    "    \n",
    "    done = False\n",
    "    steps_since_trigger = 0\n",
    "    for step in range(200):\n",
    "        steps_since_trigger += 1\n",
    "        positive_action_idxs = trainer.env._positive_actions_idx()\n",
    "        if (trainer.env.get_ac_dim() - 1) in positive_action_idxs:\n",
    "            action = trainer.env.actions[-1]\n",
    "            dist.append(steps_since_trigger)\n",
    "            print(steps_since_trigger, end = \", \")\n",
    "            steps_since_trigger = 0\n",
    "        elif steps_since_trigger > 40:\n",
    "            trainer.env.reset()\n",
    "            early_terminated += 1\n",
    "            steps_since_trigger = 0\n",
    "            continue\n",
    "        else:\n",
    "            action = trainer.env.get_random_expert_action()\n",
    "        \n",
    "        _, _, done = trainer.env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    print(\"\\n{} unfound instances out of {}\".format(len(trainer.env.target_bboxs), len(trainer.env.orig_target_bboxs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist, bins = np.arange(0,41), )\n",
    "plt.title(\"Stretchy Zoom ({} instances)\".format(len(dist)))\n",
    "plt.xlabel(\"Number of steps to localize agent\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"stretchy_zoom_dist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiagent",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
